{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDC- Part 01 - Les donnees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMNmqKxPvXImkwommWL/Gfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QSTOM-IT/datascience/blob/master/EDC_Part_01_Les_donnees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bMO0XJhnGJ"
      },
      "source": [
        "# **DATA SCIENCE | MACHINE LEARNING : ETUDE DE CAS**\r\n",
        "> Aurélien VANNIEUWENHUYZE pour Qstom-IT - wwww.qstom-it.com\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmtqze_FrYFg"
      },
      "source": [
        "#### **Les objectifs visés**\r\n",
        "L'objectif de cette étude de cas est de mettre en pratique les notions de statistiques, de Machine Learning et de Deep Learning.\r\n",
        "\r\n",
        "#### **A qui s'adresse cette étude de cas ?**\r\n",
        "Cette étude de cas s'adresse à toute personne souhaitant découvrir la mise en oeuvre de la Data Science à travers un projet 100% pratique.\r\n",
        "\r\n",
        "#### **Quels sont les pré-requis ?**\r\n",
        "Quelques notions de programmation en langage python, en Machine Learning et en Deep Learning sont requise pour apréhender sereinement cette étude de cas.\r\n",
        "\r\n",
        "#### **Methodes pédagogique**\r\n",
        "Cette étude de cas est réalisée en plusieurs étapes devant être réalisées dans l'ordre afin de bien comprendre les concepts énoncés. \r\n",
        "\r\n",
        "#### **Données est objectifs à atteindre**\r\n",
        "Le dataset utilisé contient des informations sur les clients d'une compagnie d'assurance. \r\n",
        "Les données se composent de 86 variables et comprennent des données sur l'utilisation des produits et des données sociodémographiques \r\n",
        "\r\n",
        "Les objectifs de cette étude cas sera de réaliser :\r\n",
        "- Une segmentation de clientèle\r\n",
        "- Une prédiction d'un score d'appétance de souscription de contrat d'assurance\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mdCCXD_wJwE"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYgXmC33iag5"
      },
      "source": [
        "### **1: CHARGEMENT DU FICHIER DE DONNEES DEPUIS LE WEB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X0YioUniqkO",
        "outputId": "9607390e-4df7-41f1-f143-afd756175912"
      },
      "source": [
        "\r\n",
        "#Le fichier sera télécharger dans le répertoire /content/EDC_Dataset.txt \r\n",
        "!wget EDC_Dataset.txt https://QSTOM-IT.com/echanges/etude_de_cas/EDC_Dataset.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-28 17:17:27--  http://edc_dataset.txt/\n",
            "Resolving edc_dataset.txt (edc_dataset.txt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘edc_dataset.txt’\n",
            "--2021-02-28 17:17:28--  https://qstom-it.com/echanges/etude_de_cas/EDC_Dataset.txt\n",
            "Resolving qstom-it.com (qstom-it.com)... 146.88.237.34\n",
            "Connecting to qstom-it.com (qstom-it.com)|146.88.237.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1006151 (983K) [text/plain]\n",
            "Saving to: ‘EDC_Dataset.txt’\n",
            "\n",
            "EDC_Dataset.txt     100%[===================>] 982.57K  1.12MB/s    in 0.9s    \n",
            "\n",
            "2021-02-28 17:17:29 (1.12 MB/s) - ‘EDC_Dataset.txt’ saved [1006151/1006151]\n",
            "\n",
            "FINISHED --2021-02-28 17:17:29--\n",
            "Total wall clock time: 1.7s\n",
            "Downloaded: 1 files, 983K in 0.9s (1.12 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEhPpzmBlTLa"
      },
      "source": [
        "### **2: CONVERSION DU FICHIER TEXTE EN UN DATAFRAME PANDAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kugr-I2NlS7x",
        "outputId": "19b2bf08-ccf6-4d41-f4d4-16369c665008"
      },
      "source": [
        "import pandas as pnd\r\n",
        "import os.path\r\n",
        "from os import path\r\n",
        "\r\n",
        "#Creation d'une variable contenant le chemin supposé du fichier\r\n",
        "fichierPath = '/content/EDC_Dataset.txt'\r\n",
        "\r\n",
        "#Vérification de la présence du fichier\r\n",
        "fichierPresent = path.exists(fichierPath)\r\n",
        "print (\"Le fichier est-il présent ? >> \"+str(path.exists('/content/EDC_Dataset.txt')))\r\n",
        "\r\n",
        "\r\n",
        "#Si le fichier est présent, alors on le convertit en Data Frame Pandas\r\n",
        "if(fichierPresent):\r\n",
        "\r\n",
        "  #Affichage des 5 premières lignes lignes\r\n",
        "  with open(fichierPath) as fichier:\r\n",
        "    ligne = [next(fichier) for x in range(5)]\r\n",
        "    print(ligne)\r\n",
        "  \r\n",
        "  #On constate que les éléments sont séparés par des tabulations\r\n",
        "  dataset = pnd.read_csv(fichierPath,sep=\"\\t\", header=None)\r\n",
        "\r\n",
        "  #Affichage du dataset\r\n",
        "  print(dataset.head())\r\n",
        "\r\n",
        "else :\r\n",
        "  print(\"OUPS... je ne trouve pas le fichier en question.. :-(\")\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Le fichier est-il présent ? >> True\n",
            "['33\\t1\\t3\\t2\\t8\\t0\\t5\\t1\\t3\\t7\\t0\\t2\\t1\\t2\\t6\\t1\\t2\\t7\\t1\\t0\\t1\\t2\\t5\\t2\\t1\\t1\\t2\\t6\\t1\\t1\\t8\\t8\\t0\\t1\\t8\\t1\\t0\\t4\\t5\\t0\\t0\\t4\\t3\\t0\\t0\\t0\\t6\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t5\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\n', '37\\t1\\t2\\t2\\t8\\t1\\t4\\t1\\t4\\t6\\t2\\t2\\t0\\t4\\t5\\t0\\t5\\t4\\t0\\t0\\t0\\t5\\t0\\t4\\t0\\t2\\t3\\t5\\t0\\t2\\t7\\t7\\t1\\t2\\t6\\t3\\t2\\t0\\t5\\t2\\t0\\t5\\t4\\t2\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t2\\t0\\t0\\t0\\t0\\t0\\t2\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\n', '37\\t1\\t2\\t2\\t8\\t0\\t4\\t2\\t4\\t3\\t2\\t4\\t4\\t4\\t2\\t0\\t5\\t4\\t0\\t0\\t0\\t7\\t0\\t2\\t0\\t5\\t0\\t4\\t0\\t7\\t2\\t7\\t0\\t2\\t9\\t0\\t4\\t5\\t0\\t0\\t0\\t3\\t4\\t2\\t0\\t0\\t6\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t2\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\n', '9\\t1\\t3\\t3\\t3\\t2\\t3\\t2\\t4\\t5\\t2\\t2\\t2\\t3\\t4\\t3\\t4\\t2\\t4\\t0\\t0\\t3\\t1\\t2\\t3\\t2\\t1\\t4\\t0\\t5\\t4\\t9\\t0\\t0\\t7\\t2\\t1\\t5\\t3\\t0\\t0\\t4\\t4\\t0\\t0\\t0\\t6\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t2\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\n', '40\\t1\\t4\\t2\\t10\\t1\\t4\\t1\\t4\\t7\\t1\\t2\\t2\\t4\\t4\\t5\\t4\\t0\\t0\\t5\\t4\\t0\\t0\\t0\\t9\\t0\\t0\\t0\\t0\\t4\\t5\\t6\\t2\\t1\\t5\\t4\\t0\\t0\\t9\\t0\\t0\\t6\\t3\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t6\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\n']\n",
            "   0   1   2   3   4   5   6   7   8   ...  77  78  79  80  81  82  83  84  85\n",
            "0  33   1   3   2   8   0   5   1   3  ...   0   0   1   0   0   0   0   0   0\n",
            "1  37   1   2   2   8   1   4   1   4  ...   0   0   1   0   0   0   0   0   0\n",
            "2  37   1   2   2   8   0   4   2   4  ...   0   0   1   0   0   0   0   0   0\n",
            "3   9   1   3   3   3   2   3   2   4  ...   0   0   1   0   0   0   0   0   0\n",
            "4  40   1   4   2  10   1   4   1   4  ...   0   0   1   0   0   0   0   0   0\n",
            "\n",
            "[5 rows x 86 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}